{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d493929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('df_final.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c3cd6582",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = \"2020-01-01\"\n",
    "begin_date = \"2016-01-01\"\n",
    "train = df[(df[\"game_date\"] < cutoff_date) & (df[\"game_date\"] >= begin_date)]\n",
    "test = df[df[\"game_date\"] >= cutoff_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "487d8c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_rows(df):\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        w, l = row[\"Winner\"], row[\"Loser\"]\n",
    "\n",
    "        # features\n",
    "        w_feats = {\n",
    "            \"elo_diff\": row[\"winner_elo_pre\"] - row[\"loser_elo_pre\"],\n",
    "            \"elo_surf_diff\": row[\"winner_elo_surf_pre\"] - row[\"loser_elo_surf_pre\"],\n",
    "            \"h2h_pre\": row[\"h2h_pre\"],\n",
    "            \"recent_form_diff\": row[\"recent_form_diff\"],\n",
    "            \"label\": 1  # winner perspective\n",
    "        }\n",
    "        l_feats = {\n",
    "            \"elo_diff\": row[\"loser_elo_pre\"] - row[\"winner_elo_pre\"],\n",
    "            \"elo_surf_diff\": row[\"loser_elo_surf_pre\"] - row[\"winner_elo_surf_pre\"],\n",
    "            \"h2h_pre\": -row[\"h2h_pre\"],  # flip perspective\n",
    "            \"recent_form_diff\": -row[\"recent_form_diff\"],\n",
    "            \"label\": 0  # loser perspective\n",
    "        }\n",
    "\n",
    "        rows.append(w_feats)\n",
    "        rows.append(l_feats)\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f57e57a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    5450\n",
      "0    5450\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data = make_training_rows(train)\n",
    "test_data = make_training_rows(test)\n",
    "\n",
    "X_train = train_data.drop(columns=[\"label\"])\n",
    "y_train = train_data[\"label\"]\n",
    "\n",
    "X_test = test_data.drop(columns=[\"label\"])\n",
    "y_test = test_data[\"label\"]\n",
    "\n",
    "print(y_train.value_counts())  # should now show both 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b3871718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e314bc",
   "metadata": {},
   "source": [
    "# Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1041391a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6126730103806228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.61      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4287388a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.601643598615917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.46      0.54      4624\n",
      "           1       0.58      0.74      0.65      4624\n",
      "\n",
      "    accuracy                           0.60      9248\n",
      "   macro avg       0.61      0.60      0.59      9248\n",
      "weighted avg       0.61      0.60      0.59      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                    SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aa122937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6126730103806228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.61      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "model = RidgeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "657339c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.38538062283737023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.39      0.39      4624\n",
      "           1       0.39      0.39      0.39      4624\n",
      "\n",
      "    accuracy                           0.39      9248\n",
      "   macro avg       0.39      0.39      0.39      9248\n",
      "weighted avg       0.39      0.39      0.39      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "model = Perceptron(tol=1e-3, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8532de86",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2699ccaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6126730103806228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.61      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                    LinearSVC(random_state=0, tol=1e-5))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d690322",
   "metadata": {},
   "source": [
    "# Tree Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bc4847c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5367647058823529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.53      0.53      4624\n",
      "           1       0.54      0.54      0.54      4624\n",
      "\n",
      "    accuracy                           0.54      9248\n",
      "   macro avg       0.54      0.54      0.54      9248\n",
      "weighted avg       0.54      0.54      0.54      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "61c5114d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5618512110726643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.63      0.59      4624\n",
      "           1       0.57      0.50      0.53      4624\n",
      "\n",
      "    accuracy                           0.56      9248\n",
      "   macro avg       0.56      0.56      0.56      9248\n",
      "weighted avg       0.56      0.56      0.56      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "extra_tree = ExtraTreeClassifier(random_state=0)\n",
    "model = BaggingClassifier(extra_tree, random_state=0).fit(\n",
    "   X_train, y_train)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "752bf0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6151600346020761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.61      4624\n",
      "           1       0.61      0.62      0.62      4624\n",
      "\n",
      "    accuracy                           0.62      9248\n",
      "   macro avg       0.62      0.62      0.62      9248\n",
      "weighted avg       0.62      0.62      0.62      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9abb56d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.615916955017301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.61      4624\n",
      "           1       0.61      0.64      0.62      4624\n",
      "\n",
      "    accuracy                           0.62      9248\n",
      "   macro avg       0.62      0.62      0.62      9248\n",
      "weighted avg       0.62      0.62      0.62      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "    max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c58277d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6164576124567474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.62      4624\n",
      "           1       0.62      0.59      0.61      4624\n",
      "\n",
      "    accuracy                           0.62      9248\n",
      "   macro avg       0.62      0.62      0.62      9248\n",
      "weighted avg       0.62      0.62      0.62      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cff2de",
   "metadata": {},
   "source": [
    "# Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0be9c972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5741782006920415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57      4624\n",
      "           1       0.57      0.57      0.57      4624\n",
      "\n",
      "    accuracy                           0.57      9248\n",
      "   macro avg       0.57      0.57      0.57      9248\n",
      "weighted avg       0.57      0.57      0.57      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83afe222",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7bcb560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6068339100346021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.61      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d5e43294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6133217993079585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.61      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0473d02",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4c87861f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5450, number of negative: 5450\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 707\n",
      "[LightGBM] [Info] Number of data points in the train set: 10900, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Accuracy: 0.6078070934256056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.60      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb4715d",
   "metadata": {},
   "source": [
    "# Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e7df7db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6126730103806228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.61      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d43040db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.613538062283737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.61      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/souparno/Documents/basketball_prediction/basketball-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/home/souparno/Documents/basketball_prediction/basketball-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "model = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0fcc51",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a7608b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6115916955017301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.62      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=200, max_depth=6, learning_rate=0.05, eval_metric=\"logloss\"\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b03037",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8efdded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Assume your data is already loaded and split as in your prompt\n",
    "# X_train, y_train, X_test, y_test\n",
    "\n",
    "# Convert pandas DataFrames to numpy arrays\n",
    "X_train_np = X_train.values.astype(np.float32)\n",
    "y_train_np = y_train.values.astype(np.int64) # Use int64 for CrossEntropyLoss\n",
    "\n",
    "X_test_np = X_test.values.astype(np.float32)\n",
    "y_test_np = y_test.values.astype(np.int64)\n",
    "\n",
    "# Create a custom PyTorch Dataset\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create Dataset and DataLoader instances\n",
    "train_dataset = TabularDataset(X_train_np, y_train_np)\n",
    "test_dataset = TabularDataset(X_test_np, y_test_np)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define number of input features and classes\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7e013922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.6443\n",
      "Epoch 2/20, Loss: 0.6102\n",
      "Epoch 3/20, Loss: 0.6573\n",
      "Epoch 4/20, Loss: 0.5616\n",
      "Epoch 5/20, Loss: 0.6639\n",
      "Epoch 6/20, Loss: 0.7686\n",
      "Epoch 7/20, Loss: 0.7111\n",
      "Epoch 8/20, Loss: 0.5680\n",
      "Epoch 9/20, Loss: 0.5335\n",
      "Epoch 10/20, Loss: 0.6426\n",
      "Epoch 11/20, Loss: 0.6957\n",
      "Epoch 12/20, Loss: 0.7863\n",
      "Epoch 13/20, Loss: 0.5877\n",
      "Epoch 14/20, Loss: 0.7168\n",
      "Epoch 15/20, Loss: 0.7447\n",
      "Epoch 16/20, Loss: 0.5962\n",
      "Epoch 17/20, Loss: 0.6195\n",
      "Epoch 18/20, Loss: 0.5706\n",
      "Epoch 19/20, Loss: 0.6008\n",
      "Epoch 20/20, Loss: 0.6689\n",
      "Accuracy of MLP on test data: 61.21%\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim2, hidden_dim2//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim2//2, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Model, Loss, and Optimizer\n",
    "model_mlp = MLP(input_dim=input_dim, hidden_dim1=256, hidden_dim2=64, output_dim=output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_mlp.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model_mlp.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_mlp(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model_mlp.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model_mlp(X_batch)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "print(f\"Accuracy of MLP on test data: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a2af2a",
   "metadata": {},
   "source": [
    "# Stacking Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "92c089c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking accuracy: 0.614294982698962\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "stack = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('logreg', LogisticRegression()),\n",
    "        ('svc', LinearSVC()),\n",
    "        ('adb', AdaBoostClassifier(n_estimators=100, random_state=0)),\n",
    "        ('rf', RandomForestClassifier(max_depth=2, random_state=0))\n",
    "    ],\n",
    "    final_estimator=LogisticRegression()  # meta-learner\n",
    ")\n",
    "stack.fit(X_train, y_train)\n",
    "print(\"Stacking accuracy:\", stack.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c5246dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy (sklearn + MLP): 0.6130\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from sklearn stack\n",
    "sk_pred = stack.predict_proba(X_test)\n",
    "\n",
    "# Get predictions from PyTorch MLP\n",
    "mlp_pred = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, _ in test_loader:\n",
    "        probs = torch.softmax(model_mlp(X_batch), dim=1).cpu().numpy()\n",
    "        mlp_pred.append(probs)\n",
    "mlp_pred = np.vstack(mlp_pred)\n",
    "\n",
    "# Combine (average probs)\n",
    "final_pred = (sk_pred + mlp_pred) / 2\n",
    "y_final = np.argmax(final_pred, axis=1)\n",
    "\n",
    "accuracy = (y_final == y_test).mean()\n",
    "print(f\"Ensemble Accuracy (sklearn + MLP): {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "78d82e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7244\u001b[0m       \u001b[32m0.5940\u001b[0m        \u001b[35m0.6556\u001b[0m  0.1833\n",
      "      2        \u001b[36m0.6692\u001b[0m       0.5385        0.6652  0.1958\n",
      "      3        \u001b[36m0.6524\u001b[0m       \u001b[32m0.6647\u001b[0m        \u001b[35m0.6174\u001b[0m  0.1654\n",
      "      4        \u001b[36m0.6470\u001b[0m       \u001b[32m0.6702\u001b[0m        0.6180  0.1729\n",
      "      5        \u001b[36m0.6437\u001b[0m       0.6670        0.6175  0.1822\n",
      "      6        0.6441       0.6665        \u001b[35m0.6173\u001b[0m  0.1594\n",
      "      7        0.6441       0.6665        0.6175  0.1521\n",
      "      8        \u001b[36m0.6436\u001b[0m       0.6670        \u001b[35m0.6173\u001b[0m  0.1740\n",
      "      9        0.6437       0.6674        0.6174  0.1780\n",
      "     10        0.6453       0.6651        0.6178  0.1434\n",
      "     11        0.6445       0.6697        0.6174  0.1436\n",
      "     12        0.6441       0.6661        \u001b[35m0.6172\u001b[0m  0.1432\n",
      "     13        0.6445       0.6651        0.6173  0.1434\n",
      "     14        0.6441       0.6679        0.6173  0.1449\n",
      "     15        0.6436       0.6661        \u001b[35m0.6172\u001b[0m  0.1437\n",
      "     16        0.6440       0.6665        \u001b[35m0.6170\u001b[0m  0.1439\n",
      "     17        0.6436       0.6573        0.6184  0.1464\n",
      "     18        0.6499       0.6619        0.6184  0.1464\n",
      "     19        0.6466       0.6638        0.6176  0.1465\n",
      "     20        0.6452       0.6596        0.6183  0.1454\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7524\u001b[0m       \u001b[32m0.4358\u001b[0m        \u001b[35m0.7187\u001b[0m  0.1607\n",
      "      2        \u001b[36m0.6723\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6928\u001b[0m  0.1364\n",
      "      3        0.6814       0.4994        0.7712  0.1374\n",
      "      4        \u001b[36m0.6660\u001b[0m       \u001b[32m0.6158\u001b[0m        \u001b[35m0.6723\u001b[0m  0.1363\n",
      "      5        \u001b[36m0.6528\u001b[0m       0.6124        \u001b[35m0.6488\u001b[0m  0.1374\n",
      "      6        \u001b[36m0.6498\u001b[0m       0.6130        \u001b[35m0.6484\u001b[0m  0.1369\n",
      "      7        \u001b[36m0.6471\u001b[0m       0.6153        0.6507  0.1340\n",
      "      8        \u001b[36m0.6463\u001b[0m       0.6118        0.6511  0.1302\n",
      "      9        0.6468       0.6153        0.6523  0.1366\n",
      "     10        \u001b[36m0.6460\u001b[0m       0.6124        0.6485  0.1388\n",
      "     11        \u001b[36m0.6452\u001b[0m       0.6107        0.6509  0.1367\n",
      "     12        0.6462       0.6107        0.6551  0.1366\n",
      "     13        0.6458       0.6118        0.6522  0.1516\n",
      "     14        0.6460       0.6135        0.6488  0.1378\n",
      "     15        0.6458       0.6118        0.6486  0.1370\n",
      "     16        0.6456       0.6135        \u001b[35m0.6484\u001b[0m  0.1390\n",
      "     17        0.6455       0.6130        \u001b[35m0.6483\u001b[0m  0.1509\n",
      "     18        0.6453       0.6135        0.6490  0.1489\n",
      "     19        0.6452       0.6130        0.6492  0.1389\n",
      "     20        0.6453       0.6147        \u001b[35m0.6482\u001b[0m  0.1389\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7041\u001b[0m       \u001b[32m0.5080\u001b[0m        \u001b[35m0.6798\u001b[0m  0.1150\n",
      "      2        \u001b[36m0.6672\u001b[0m       \u001b[32m0.5648\u001b[0m        \u001b[35m0.6568\u001b[0m  0.1139\n",
      "      3        \u001b[36m0.6582\u001b[0m       0.5287        0.6607  0.1253\n",
      "      4        \u001b[36m0.6550\u001b[0m       \u001b[32m0.6571\u001b[0m        \u001b[35m0.6172\u001b[0m  0.1391\n",
      "      5        \u001b[36m0.6448\u001b[0m       \u001b[32m0.6617\u001b[0m        \u001b[35m0.6147\u001b[0m  0.1563\n",
      "      6        \u001b[36m0.6436\u001b[0m       \u001b[32m0.6703\u001b[0m        \u001b[35m0.6144\u001b[0m  0.1365\n",
      "      7        \u001b[36m0.6425\u001b[0m       0.6697        \u001b[35m0.6144\u001b[0m  0.1388\n",
      "      8        0.6425       0.6674        \u001b[35m0.6143\u001b[0m  0.1369\n",
      "      9        \u001b[36m0.6424\u001b[0m       0.6646        0.6145  0.1350\n",
      "     10        \u001b[36m0.6422\u001b[0m       0.6634        0.6145  0.1355\n",
      "     11        \u001b[36m0.6419\u001b[0m       0.6651        0.6145  0.1366\n",
      "     12        \u001b[36m0.6418\u001b[0m       0.6657        0.6146  0.1393\n",
      "     13        0.6420       0.6680        0.6144  0.1431\n",
      "     14        0.6427       0.6646        0.6146  0.1342\n",
      "     15        0.6420       0.6651        0.6146  0.1366\n",
      "     16        0.6419       0.6663        0.6145  0.1392\n",
      "     17        0.6459       0.6628        0.6240  0.1391\n",
      "     18        0.6498       0.6646        0.6158  0.1327\n",
      "     19        0.6435       0.6623        0.6146  0.1382\n",
      "     20        0.6424       0.6651        0.6144  0.1479\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8421\u001b[0m       \u001b[32m0.3974\u001b[0m        \u001b[35m0.7402\u001b[0m  0.1393\n",
      "      2        \u001b[36m0.6856\u001b[0m       \u001b[32m0.6646\u001b[0m        \u001b[35m0.6246\u001b[0m  0.1491\n",
      "      3        \u001b[36m0.6590\u001b[0m       0.5052        0.6787  0.1371\n",
      "      4        \u001b[36m0.6547\u001b[0m       0.6623        \u001b[35m0.6182\u001b[0m  0.1294\n",
      "      5        \u001b[36m0.6448\u001b[0m       0.6634        0.6186  0.1179\n",
      "      6        \u001b[36m0.6442\u001b[0m       \u001b[32m0.6663\u001b[0m        \u001b[35m0.6159\u001b[0m  0.1229\n",
      "      7        \u001b[36m0.6439\u001b[0m       0.6158        0.6499  0.1171\n",
      "      8        0.6487       0.6628        \u001b[35m0.6148\u001b[0m  0.1270\n",
      "      9        \u001b[36m0.6434\u001b[0m       0.6617        0.6156  0.1365\n",
      "     10        0.6443       0.6657        0.6175  0.1455\n",
      "     11        0.6434       \u001b[32m0.6669\u001b[0m        0.6154  0.1333\n",
      "     12        \u001b[36m0.6431\u001b[0m       0.6669        0.6173  0.1404\n",
      "     13        \u001b[36m0.6430\u001b[0m       0.6663        \u001b[35m0.6147\u001b[0m  0.1352\n",
      "     14        \u001b[36m0.6426\u001b[0m       0.6640        0.6148  0.1395\n",
      "     15        \u001b[36m0.6426\u001b[0m       0.6669        0.6151  0.1259\n",
      "     16        0.6430       0.6634        0.6153  0.1374\n",
      "     17        0.6432       0.6663        0.6147  0.1359\n",
      "     18        0.6427       0.6663        \u001b[35m0.6146\u001b[0m  0.1380\n",
      "     19        \u001b[36m0.6426\u001b[0m       0.6617        0.6147  0.1345\n",
      "     20        0.6426       0.6617        0.6149  0.1143\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.9192\u001b[0m       \u001b[32m0.4788\u001b[0m        \u001b[35m0.7487\u001b[0m  0.1410\n",
      "      2        \u001b[36m0.6886\u001b[0m       \u001b[32m0.5877\u001b[0m        \u001b[35m0.6537\u001b[0m  0.1360\n",
      "      3        0.6965       \u001b[32m0.6623\u001b[0m        \u001b[35m0.6404\u001b[0m  0.1483\n",
      "      4        \u001b[36m0.6622\u001b[0m       0.6594        \u001b[35m0.6205\u001b[0m  0.1391\n",
      "      5        \u001b[36m0.6529\u001b[0m       0.6525        \u001b[35m0.6187\u001b[0m  0.1420\n",
      "      6        \u001b[36m0.6491\u001b[0m       0.6588        \u001b[35m0.6174\u001b[0m  0.1363\n",
      "      7        \u001b[36m0.6466\u001b[0m       0.6548        0.6181  0.1475\n",
      "      8        \u001b[36m0.6457\u001b[0m       0.6571        \u001b[35m0.6174\u001b[0m  0.1353\n",
      "      9        \u001b[36m0.6448\u001b[0m       0.6537        \u001b[35m0.6165\u001b[0m  0.1346\n",
      "     10        0.6452       0.6600        0.6171  0.1367\n",
      "     11        0.6486       \u001b[32m0.6628\u001b[0m        \u001b[35m0.6163\u001b[0m  0.1395\n",
      "     12        \u001b[36m0.6448\u001b[0m       \u001b[32m0.6640\u001b[0m        \u001b[35m0.6153\u001b[0m  0.1316\n",
      "     13        \u001b[36m0.6432\u001b[0m       0.6611        \u001b[35m0.6147\u001b[0m  0.1358\n",
      "     14        \u001b[36m0.6427\u001b[0m       0.6611        0.6148  0.1350\n",
      "     15        0.6427       0.6611        \u001b[35m0.6143\u001b[0m  0.1525\n",
      "     16        0.6451       0.6606        0.6173  0.1356\n",
      "     17        0.6460       \u001b[32m0.6646\u001b[0m        0.6166  0.1567\n",
      "     18        0.6463       \u001b[32m0.6674\u001b[0m        0.6194  0.1387\n",
      "     19        0.6455       0.6611        0.6168  0.1182\n",
      "     20        0.6440       0.6628        0.6167  0.1441\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7016\u001b[0m       \u001b[32m0.6623\u001b[0m        \u001b[35m0.6585\u001b[0m  0.1341\n",
      "      2        \u001b[36m0.6669\u001b[0m       0.6594        \u001b[35m0.6174\u001b[0m  0.1342\n",
      "      3        \u001b[36m0.6575\u001b[0m       \u001b[32m0.6628\u001b[0m        0.6176  0.1273\n",
      "      4        \u001b[36m0.6485\u001b[0m       \u001b[32m0.6640\u001b[0m        0.6194  0.1394\n",
      "      5        \u001b[36m0.6480\u001b[0m       \u001b[32m0.6657\u001b[0m        0.6226  0.1333\n",
      "      6        \u001b[36m0.6470\u001b[0m       0.6646        0.6197  0.1344\n",
      "      7        0.6487       0.6617        0.6220  0.1317\n",
      "      8        0.6487       0.6623        0.6213  0.1321\n",
      "      9        \u001b[36m0.6464\u001b[0m       0.6651        0.6222  0.1237\n",
      "     10        0.6481       \u001b[32m0.6663\u001b[0m        0.6210  0.1303\n",
      "     11        0.6472       \u001b[32m0.6692\u001b[0m        0.6283  0.1350\n",
      "     12        \u001b[36m0.6455\u001b[0m       0.6686        0.6251  0.1270\n",
      "     13        \u001b[36m0.6452\u001b[0m       0.6686        0.6272  0.1136\n",
      "     14        \u001b[36m0.6449\u001b[0m       0.6692        0.6217  0.1146\n",
      "     15        0.6473       0.6674        0.6220  0.1351\n",
      "     16        0.6463       0.6657        0.6272  0.1186\n",
      "     17        0.6457       0.6663        0.6283  0.1145\n",
      "     18        0.6455       0.6669        0.6283  0.1192\n",
      "     19        0.6453       0.6663        0.6274  0.1238\n",
      "     20        0.6453       0.6634        0.6275  0.1259\n",
      "Stacked Ensemble Accuracy: 0.6141868512110726\n"
     ]
    }
   ],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "# Wrap your MLP into sklearn-compatible estimator\n",
    "net = NeuralNetClassifier(\n",
    "    MLP,\n",
    "    module__input_dim=input_dim,\n",
    "    module__hidden_dim1=256,\n",
    "    module__hidden_dim2=64,\n",
    "    module__output_dim=output_dim,\n",
    "    max_epochs=20,\n",
    "    lr=0.001,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    batch_size=64,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "# Add it to stacking ensemble\n",
    "stack = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('logreg', LogisticRegression(max_iter=1000)),\n",
    "        ('svc', LinearSVC()),\n",
    "        ('adb', AdaBoostClassifier(n_estimators=100, random_state=0)),\n",
    "        ('rf', RandomForestClassifier(max_depth=2, random_state=0)),\n",
    "        ('mlp', net)  # torch model wrapped\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=1000)\n",
    ")\n",
    "\n",
    "stack.fit(X_train_np, y_train_np)\n",
    "print(\"Stacked Ensemble Accuracy:\", stack.score(X_test_np, y_test_np))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "452504b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6150519031141869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.61      4624\n",
      "           1       0.61      0.62      0.62      4624\n",
      "\n",
      "    accuracy                           0.62      9248\n",
      "   macro avg       0.62      0.62      0.62      9248\n",
      "weighted avg       0.62      0.62      0.62      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8b6085f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking accuracy: 0.6161332179930796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.61      4624\n",
      "           1       0.61      0.62      0.62      4624\n",
      "\n",
      "    accuracy                           0.62      9248\n",
      "   macro avg       0.62      0.62      0.62      9248\n",
      "weighted avg       0.62      0.62      0.62      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "stack = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('logreg', LogisticRegression()),\n",
    "        ('adb', AdaBoostClassifier(n_estimators=100, random_state=42)),\n",
    "        ('mlp', MLPClassifier(random_state=42))\n",
    "    ],\n",
    "    final_estimator=LogisticRegression()  # meta-learner\n",
    ")\n",
    "stack.fit(X_train, y_train)\n",
    "print(\"Stacking accuracy:\", stack.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basketball-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
