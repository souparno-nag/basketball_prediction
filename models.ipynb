{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d493929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('df_final.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3cd6582",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = \"2020-01-01\"\n",
    "begin_date = \"2016-01-01\"\n",
    "train = df[(df[\"game_date\"] < cutoff_date) & (df[\"game_date\"] >= begin_date)]\n",
    "test = df[df[\"game_date\"] >= cutoff_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "487d8c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_rows(df):\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        w, l = row[\"Winner\"], row[\"Loser\"]\n",
    "\n",
    "        # features\n",
    "        w_feats = {\n",
    "            \"elo_diff\": row[\"winner_elo_pre\"] - row[\"loser_elo_pre\"],\n",
    "            \"elo_surf_diff\": row[\"winner_elo_surf_pre\"] - row[\"loser_elo_surf_pre\"],\n",
    "            \"h2h_pre\": row[\"h2h_pre\"],\n",
    "            \"recent_form_diff\": row[\"recent_form_diff\"],\n",
    "            \"label\": 1  # winner perspective\n",
    "        }\n",
    "        l_feats = {\n",
    "            \"elo_diff\": row[\"loser_elo_pre\"] - row[\"winner_elo_pre\"],\n",
    "            \"elo_surf_diff\": row[\"loser_elo_surf_pre\"] - row[\"winner_elo_surf_pre\"],\n",
    "            \"h2h_pre\": -row[\"h2h_pre\"],  # flip perspective\n",
    "            \"recent_form_diff\": -row[\"recent_form_diff\"],\n",
    "            \"label\": 0  # loser perspective\n",
    "        }\n",
    "\n",
    "        rows.append(w_feats)\n",
    "        rows.append(l_feats)\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f57e57a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    5450\n",
      "0    5450\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data = make_training_rows(train)\n",
    "test_data = make_training_rows(test)\n",
    "\n",
    "X_train = train_data.drop(columns=[\"label\"])\n",
    "y_train = train_data[\"label\"]\n",
    "\n",
    "X_test = test_data.drop(columns=[\"label\"])\n",
    "y_test = test_data[\"label\"]\n",
    "\n",
    "print(y_train.value_counts())  # should now show both 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3871718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e314bc",
   "metadata": {},
   "source": [
    "# Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1041391a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6126730103806228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.61      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4287388a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6126730103806228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60      4624\n",
      "           1       0.61      0.65      0.63      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                    SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa122937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6126730103806228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.61      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "model = RidgeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "657339c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.38538062283737023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.39      0.39      4624\n",
      "           1       0.39      0.39      0.39      4624\n",
      "\n",
      "    accuracy                           0.39      9248\n",
      "   macro avg       0.39      0.39      0.39      9248\n",
      "weighted avg       0.39      0.39      0.39      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "model = Perceptron(tol=1e-3, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8532de86",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2699ccaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6126730103806228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.61      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                    LinearSVC(random_state=0, tol=1e-5))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d690322",
   "metadata": {},
   "source": [
    "# Tree Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc4847c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5367647058823529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.53      0.53      4624\n",
      "           1       0.54      0.54      0.54      4624\n",
      "\n",
      "    accuracy                           0.54      9248\n",
      "   macro avg       0.54      0.54      0.54      9248\n",
      "weighted avg       0.54      0.54      0.54      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61c5114d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5618512110726643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.63      0.59      4624\n",
      "           1       0.57      0.50      0.53      4624\n",
      "\n",
      "    accuracy                           0.56      9248\n",
      "   macro avg       0.56      0.56      0.56      9248\n",
      "weighted avg       0.56      0.56      0.56      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "extra_tree = ExtraTreeClassifier(random_state=0)\n",
    "model = BaggingClassifier(extra_tree, random_state=0).fit(\n",
    "   X_train, y_train)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "752bf0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6151600346020761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.61      4624\n",
      "           1       0.61      0.62      0.62      4624\n",
      "\n",
      "    accuracy                           0.62      9248\n",
      "   macro avg       0.62      0.62      0.62      9248\n",
      "weighted avg       0.62      0.62      0.62      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9abb56d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.615916955017301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.61      4624\n",
      "           1       0.61      0.64      0.62      4624\n",
      "\n",
      "    accuracy                           0.62      9248\n",
      "   macro avg       0.62      0.62      0.62      9248\n",
      "weighted avg       0.62      0.62      0.62      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "    max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c58277d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6164576124567474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.62      4624\n",
      "           1       0.62      0.59      0.61      4624\n",
      "\n",
      "    accuracy                           0.62      9248\n",
      "   macro avg       0.62      0.62      0.62      9248\n",
      "weighted avg       0.62      0.62      0.62      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cff2de",
   "metadata": {},
   "source": [
    "# Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0be9c972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5741782006920415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57      4624\n",
      "           1       0.57      0.57      0.57      4624\n",
      "\n",
      "    accuracy                           0.57      9248\n",
      "   macro avg       0.57      0.57      0.57      9248\n",
      "weighted avg       0.57      0.57      0.57      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83afe222",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bcb560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6068339100346021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.61      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5e43294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6133217993079585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.61      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0473d02",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c87861f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5450, number of negative: 5450\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 707\n",
      "[LightGBM] [Info] Number of data points in the train set: 10900, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Accuracy: 0.6078070934256056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.60      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb4715d",
   "metadata": {},
   "source": [
    "# Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7df7db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6126730103806228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.61      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d43040db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.613538062283737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.61      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/souparno/Documents/basketball_prediction/basketball-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/home/souparno/Documents/basketball_prediction/basketball-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "model = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0fcc51",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7608b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6115916955017301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4624\n",
      "           1       0.61      0.62      0.61      4624\n",
      "\n",
      "    accuracy                           0.61      9248\n",
      "   macro avg       0.61      0.61      0.61      9248\n",
      "weighted avg       0.61      0.61      0.61      9248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=200, max_depth=6, learning_rate=0.05, eval_metric=\"logloss\"\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b03037",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8efdded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Assume your data is already loaded and split as in your prompt\n",
    "# X_train, y_train, X_test, y_test\n",
    "\n",
    "# Convert pandas DataFrames to numpy arrays\n",
    "X_train_np = X_train.values.astype(np.float32)\n",
    "y_train_np = y_train.values.astype(np.int64) # Use int64 for CrossEntropyLoss\n",
    "\n",
    "X_test_np = X_test.values.astype(np.float32)\n",
    "y_test_np = y_test.values.astype(np.int64)\n",
    "\n",
    "# Create a custom PyTorch Dataset\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create Dataset and DataLoader instances\n",
    "train_dataset = TabularDataset(X_train_np, y_train_np)\n",
    "test_dataset = TabularDataset(X_test_np, y_test_np)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define number of input features and classes\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e013922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.7642\n",
      "Epoch 2/20, Loss: 0.8948\n",
      "Epoch 3/20, Loss: 0.8299\n",
      "Epoch 4/20, Loss: 0.6999\n",
      "Epoch 5/20, Loss: 0.6923\n",
      "Epoch 6/20, Loss: 0.6099\n",
      "Epoch 7/20, Loss: 0.5960\n",
      "Epoch 8/20, Loss: 0.6636\n",
      "Epoch 9/20, Loss: 0.6682\n",
      "Epoch 10/20, Loss: 0.6256\n",
      "Epoch 11/20, Loss: 0.6260\n",
      "Epoch 12/20, Loss: 0.7220\n",
      "Epoch 13/20, Loss: 0.5828\n",
      "Epoch 14/20, Loss: 0.6118\n",
      "Epoch 15/20, Loss: 0.4654\n",
      "Epoch 16/20, Loss: 0.5154\n",
      "Epoch 17/20, Loss: 0.6035\n",
      "Epoch 18/20, Loss: 0.6113\n",
      "Epoch 19/20, Loss: 0.6205\n",
      "Epoch 20/20, Loss: 0.6997\n",
      "Accuracy of MLP on test data: 61.40%\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim2, hidden_dim2//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim2//2, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Model, Loss, and Optimizer\n",
    "model_mlp = MLP(input_dim=input_dim, hidden_dim1=256, hidden_dim2=64, output_dim=output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_mlp.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model_mlp.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_mlp(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model_mlp.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model_mlp(X_batch)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "print(f\"Accuracy of MLP on test data: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a2af2a",
   "metadata": {},
   "source": [
    "# Stacking Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92c089c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking accuracy: 0.614294982698962\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "stack = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('logreg', LogisticRegression()),\n",
    "        ('svc', LinearSVC()),\n",
    "        ('adb', AdaBoostClassifier(n_estimators=100, random_state=0)),\n",
    "        ('rf', RandomForestClassifier(max_depth=2, random_state=0))\n",
    "    ],\n",
    "    final_estimator=LogisticRegression()  # meta-learner\n",
    ")\n",
    "stack.fit(X_train, y_train)\n",
    "print(\"Stacking accuracy:\", stack.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5246dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy (sklearn + MLP): 0.6126\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from sklearn stack\n",
    "sk_pred = stack.predict_proba(X_test)\n",
    "\n",
    "# Get predictions from PyTorch MLP\n",
    "mlp_pred = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, _ in test_loader:\n",
    "        probs = torch.softmax(model_mlp(X_batch), dim=1).cpu().numpy()\n",
    "        mlp_pred.append(probs)\n",
    "mlp_pred = np.vstack(mlp_pred)\n",
    "\n",
    "# Combine (average probs)\n",
    "final_pred = (sk_pred + mlp_pred) / 2\n",
    "y_final = np.argmax(final_pred, axis=1)\n",
    "\n",
    "accuracy = (y_final == y_test).mean()\n",
    "print(f\"Ensemble Accuracy (sklearn + MLP): {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78d82e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7092\u001b[0m       \u001b[32m0.6514\u001b[0m        \u001b[35m0.6301\u001b[0m  0.6385\n",
      "      2        \u001b[36m0.6627\u001b[0m       \u001b[32m0.6537\u001b[0m        \u001b[35m0.6216\u001b[0m  0.6198\n",
      "      3        \u001b[36m0.6512\u001b[0m       0.6505        0.6234  0.7988\n",
      "      4        \u001b[36m0.6493\u001b[0m       \u001b[32m0.6560\u001b[0m        \u001b[35m0.6196\u001b[0m  0.7085\n",
      "      5        \u001b[36m0.6479\u001b[0m       \u001b[32m0.6619\u001b[0m        \u001b[35m0.6192\u001b[0m  0.4398\n",
      "      6        \u001b[36m0.6461\u001b[0m       0.6601        \u001b[35m0.6179\u001b[0m  0.5049\n",
      "      7        \u001b[36m0.6453\u001b[0m       \u001b[32m0.6638\u001b[0m        \u001b[35m0.6178\u001b[0m  0.5041\n",
      "      8        0.6453       \u001b[32m0.6670\u001b[0m        \u001b[35m0.6174\u001b[0m  0.5191\n",
      "      9        \u001b[36m0.6451\u001b[0m       0.6670        0.6178  0.4892\n",
      "     10        \u001b[36m0.6450\u001b[0m       0.6670        0.6181  0.4205\n",
      "     11        \u001b[36m0.6449\u001b[0m       0.6610        0.6184  0.4523\n",
      "     12        0.6460       \u001b[32m0.6688\u001b[0m        0.6189  0.4805\n",
      "     13        0.6450       0.6656        0.6176  0.4346\n",
      "     14        \u001b[36m0.6448\u001b[0m       0.6656        0.6179  0.4355\n",
      "     15        \u001b[36m0.6446\u001b[0m       \u001b[32m0.6711\u001b[0m        0.6175  0.5095\n",
      "     16        \u001b[36m0.6445\u001b[0m       0.6633        0.6180  0.4313\n",
      "     17        0.6448       0.6697        \u001b[35m0.6173\u001b[0m  0.4055\n",
      "     18        \u001b[36m0.6443\u001b[0m       0.6674        0.6175  0.4570\n",
      "     19        \u001b[36m0.6443\u001b[0m       0.6647        0.6178  0.4547\n",
      "     20        0.6447       0.6647        0.6175  0.5325\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7328\u001b[0m       \u001b[32m0.6204\u001b[0m        \u001b[35m0.6625\u001b[0m  0.3857\n",
      "      2        \u001b[36m0.6735\u001b[0m       \u001b[32m0.6210\u001b[0m        0.6633  0.3760\n",
      "      3        \u001b[36m0.6592\u001b[0m       0.6135        0.6723  0.4650\n",
      "      4        \u001b[36m0.6483\u001b[0m       0.6153        \u001b[35m0.6532\u001b[0m  0.3242\n",
      "      5        \u001b[36m0.6465\u001b[0m       0.6118        \u001b[35m0.6505\u001b[0m  0.3338\n",
      "      6        \u001b[36m0.6458\u001b[0m       0.6107        \u001b[35m0.6483\u001b[0m  0.3652\n",
      "      7        0.6465       0.6107        0.6525  0.3360\n",
      "      8        0.6461       0.6078        \u001b[35m0.6481\u001b[0m  0.3297\n",
      "      9        0.6458       0.6107        \u001b[35m0.6478\u001b[0m  0.3214\n",
      "     10        0.6458       0.6084        0.6480  0.3059\n",
      "     11        \u001b[36m0.6457\u001b[0m       0.6089        0.6479  0.3097\n",
      "     12        0.6458       0.6084        0.6483  0.3087\n",
      "     13        \u001b[36m0.6456\u001b[0m       0.6124        0.6479  0.3068\n",
      "     14        0.6456       0.6112        0.6481  0.3179\n",
      "     15        \u001b[36m0.6455\u001b[0m       0.6095        0.6482  0.3581\n",
      "     16        0.6456       0.6118        0.6498  0.3697\n",
      "     17        \u001b[36m0.6454\u001b[0m       0.6112        0.6481  0.3804\n",
      "     18        \u001b[36m0.6453\u001b[0m       0.6107        0.6484  0.3615\n",
      "     19        \u001b[36m0.6452\u001b[0m       0.6112        0.6481  0.3657\n",
      "     20        \u001b[36m0.6452\u001b[0m       0.6101        0.6485  0.3732\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7492\u001b[0m       \u001b[32m0.6273\u001b[0m        \u001b[35m0.6619\u001b[0m  0.3741\n",
      "      2        \u001b[36m0.6819\u001b[0m       0.5029        0.6707  0.3243\n",
      "      3        \u001b[36m0.6629\u001b[0m       \u001b[32m0.6617\u001b[0m        \u001b[35m0.6262\u001b[0m  0.3131\n",
      "      4        \u001b[36m0.6601\u001b[0m       0.6600        \u001b[35m0.6169\u001b[0m  0.3182\n",
      "      5        \u001b[36m0.6455\u001b[0m       \u001b[32m0.6657\u001b[0m        0.6173  0.3725\n",
      "      6        \u001b[36m0.6452\u001b[0m       0.6634        \u001b[35m0.6148\u001b[0m  0.4863\n",
      "      7        \u001b[36m0.6447\u001b[0m       0.6594        0.6163  0.3165\n",
      "      8        0.6452       0.6606        0.6168  0.4769\n",
      "      9        0.6451       0.6583        0.6173  0.3991\n",
      "     10        0.6454       0.6588        0.6161  0.4188\n",
      "     11        0.6451       0.6594        0.6157  0.4114\n",
      "     12        0.6460       0.6537        0.6176  0.3608\n",
      "     13        0.6453       0.6531        0.6163  0.3976\n",
      "     14        0.6451       0.6531        0.6163  0.3835\n",
      "     15        0.6453       0.6525        0.6162  0.4256\n",
      "     16        0.6450       0.6600        0.6162  0.3520\n",
      "     17        0.6453       0.6560        0.6164  0.4096\n",
      "     18        0.6452       0.6519        0.6164  0.4067\n",
      "     19        0.6458       0.6537        0.6164  0.4026\n",
      "     20        0.6450       0.6565        0.6160  0.3463\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7639\u001b[0m       \u001b[32m0.5040\u001b[0m        \u001b[35m0.6756\u001b[0m  0.4727\n",
      "      2        \u001b[36m0.6811\u001b[0m       0.4994        0.6804  0.3698\n",
      "      3        \u001b[36m0.6648\u001b[0m       \u001b[32m0.6657\u001b[0m        \u001b[35m0.6315\u001b[0m  0.3965\n",
      "      4        \u001b[36m0.6464\u001b[0m       0.6640        \u001b[35m0.6171\u001b[0m  0.3826\n",
      "      5        \u001b[36m0.6439\u001b[0m       0.6657        0.6180  0.3911\n",
      "      6        \u001b[36m0.6437\u001b[0m       \u001b[32m0.6669\u001b[0m        \u001b[35m0.6160\u001b[0m  0.3871\n",
      "      7        \u001b[36m0.6437\u001b[0m       0.6646        0.6165  0.3749\n",
      "      8        \u001b[36m0.6437\u001b[0m       0.6657        \u001b[35m0.6151\u001b[0m  0.3811\n",
      "      9        \u001b[36m0.6436\u001b[0m       0.6669        0.6153  0.3348\n",
      "     10        0.6438       \u001b[32m0.6680\u001b[0m        0.6156  0.3193\n",
      "     11        0.6460       0.6577        0.6250  0.3344\n",
      "     12        0.6459       0.6669        0.6160  0.3320\n",
      "     13        0.6439       0.6669        0.6170  0.3437\n",
      "     14        0.6440       0.6657        0.6152  0.3234\n",
      "     15        \u001b[36m0.6436\u001b[0m       0.6651        0.6156  0.3547\n",
      "     16        \u001b[36m0.6431\u001b[0m       0.6657        \u001b[35m0.6150\u001b[0m  0.3293\n",
      "     17        \u001b[36m0.6429\u001b[0m       0.6651        \u001b[35m0.6149\u001b[0m  0.3501\n",
      "     18        \u001b[36m0.6428\u001b[0m       0.6657        \u001b[35m0.6149\u001b[0m  0.3693\n",
      "     19        \u001b[36m0.6427\u001b[0m       0.6640        \u001b[35m0.6148\u001b[0m  0.3738\n",
      "     20        \u001b[36m0.6426\u001b[0m       0.6663        0.6148  0.4111\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7600\u001b[0m       \u001b[32m0.4989\u001b[0m        \u001b[35m0.6974\u001b[0m  0.4329\n",
      "      2        \u001b[36m0.6807\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6789\u001b[0m  0.4034\n",
      "      3        \u001b[36m0.6648\u001b[0m       \u001b[32m0.5654\u001b[0m        \u001b[35m0.6600\u001b[0m  0.4130\n",
      "      4        \u001b[36m0.6625\u001b[0m       \u001b[32m0.6600\u001b[0m        \u001b[35m0.6181\u001b[0m  0.4565\n",
      "      5        \u001b[36m0.6517\u001b[0m       0.6565        \u001b[35m0.6154\u001b[0m  0.3764\n",
      "      6        \u001b[36m0.6458\u001b[0m       0.6594        0.6174  0.3322\n",
      "      7        \u001b[36m0.6444\u001b[0m       0.6577        0.6181  0.4082\n",
      "      8        \u001b[36m0.6439\u001b[0m       0.6554        0.6176  0.3591\n",
      "      9        0.6439       0.6583        0.6172  0.4622\n",
      "     10        0.6446       0.6531        0.6163  0.4297\n",
      "     11        0.6453       0.6600        0.6158  0.4941\n",
      "     12        \u001b[36m0.6425\u001b[0m       0.6583        \u001b[35m0.6142\u001b[0m  0.5830\n",
      "     13        0.6435       0.6594        0.6144  0.5461\n",
      "     14        0.6452       \u001b[32m0.6606\u001b[0m        0.6184  0.6193\n",
      "     15        0.6445       0.5034        0.6583  0.4249\n",
      "     16        0.6441       0.6548        0.6154  0.5677\n",
      "     17        \u001b[36m0.6423\u001b[0m       0.6588        0.6149  0.4214\n",
      "     18        \u001b[36m0.6420\u001b[0m       0.6571        0.6149  0.4931\n",
      "     19        0.6421       0.6554        0.6145  0.4397\n",
      "     20        \u001b[36m0.6420\u001b[0m       0.6594        0.6150  0.4466\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7958\u001b[0m       \u001b[32m0.6611\u001b[0m        \u001b[35m0.6719\u001b[0m  0.4891\n",
      "      2        \u001b[36m0.6692\u001b[0m       \u001b[32m0.6646\u001b[0m        \u001b[35m0.6690\u001b[0m  0.4715\n",
      "      3        \u001b[36m0.6691\u001b[0m       0.6628        \u001b[35m0.6222\u001b[0m  0.4288\n",
      "      4        \u001b[36m0.6503\u001b[0m       0.6594        \u001b[35m0.6182\u001b[0m  0.3816\n",
      "      5        \u001b[36m0.6476\u001b[0m       0.6606        \u001b[35m0.6166\u001b[0m  0.3572\n",
      "      6        0.6481       \u001b[32m0.6674\u001b[0m        \u001b[35m0.6145\u001b[0m  0.4138\n",
      "      7        \u001b[36m0.6474\u001b[0m       0.6577        0.6242  0.5135\n",
      "      8        \u001b[36m0.6464\u001b[0m       0.6663        0.6205  0.3975\n",
      "      9        0.6474       \u001b[32m0.6697\u001b[0m        0.6278  0.3423\n",
      "     10        0.6465       0.6628        0.6246  0.3744\n",
      "     11        0.6479       0.6651        0.6276  0.3674\n",
      "     12        0.6485       0.6663        0.6286  0.3536\n",
      "     13        0.6469       0.6651        0.6286  0.4244\n",
      "     14        0.6467       0.6646        0.6288  0.3654\n",
      "     15        0.6464       0.6674        0.6289  0.3492\n",
      "     16        0.6464       0.6628        0.6287  0.4114\n",
      "     17        \u001b[36m0.6463\u001b[0m       0.6651        0.6277  0.4231\n",
      "     18        \u001b[36m0.6462\u001b[0m       0.6646        0.6287  0.4914\n",
      "     19        \u001b[36m0.6462\u001b[0m       0.6646        0.6283  0.4173\n",
      "     20        \u001b[36m0.6461\u001b[0m       0.6651        0.6282  0.4451\n",
      "Stacked Ensemble Accuracy: 0.6137543252595156\n"
     ]
    }
   ],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "# Wrap your MLP into sklearn-compatible estimator\n",
    "net = NeuralNetClassifier(\n",
    "    MLP,\n",
    "    module__input_dim=input_dim,\n",
    "    module__hidden_dim1=256,\n",
    "    module__hidden_dim2=64,\n",
    "    module__output_dim=output_dim,\n",
    "    max_epochs=20,\n",
    "    lr=0.001,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    batch_size=64,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "# Add it to stacking ensemble\n",
    "stack = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('logreg', LogisticRegression(max_iter=1000)),\n",
    "        ('svc', LinearSVC()),\n",
    "        ('adb', AdaBoostClassifier(n_estimators=100, random_state=0)),\n",
    "        ('rf', RandomForestClassifier(max_depth=2, random_state=0)),\n",
    "        ('mlp', net)  # torch model wrapped\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=1000)\n",
    ")\n",
    "\n",
    "stack.fit(X_train_np, y_train_np)\n",
    "print(\"Stacked Ensemble Accuracy:\", stack.score(X_test_np, y_test_np))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basketball-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
